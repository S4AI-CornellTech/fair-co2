[
  {
    "build_commit": "4078c77f",
    "build_number": 4690,
    "cpu_info": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/Meta-Llama-3-8B/Meta-Llama-3-8B-F16.gguf",
    "model_type": "llama 8B F16",
    "model_size": 16061054976,
    "model_n_params": 8030261248,
    "n_batch": 1,
    "n_ubatch": 512,
    "n_threads": 48,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "tensor_split": "0.00",
    "use_mmap": true,
    "embeddings": false,
    "n_prompt": 128,
    "n_gen": 64,
    "test_time": "2025-02-17T07:40:14Z",
    "avg_ns": 53284677961,
    "stddev_ns": 4108800562,
    "avg_ts": 3.781596,
    "stddev_ts": 0.970783,
    "samples_ns": [ 62997460996, 62431460896, 60982717038, 42512841275, 37498909601 ],
    "samples_ts": [ 3.04774, 3.07537, 3.14843, 4.51628, 5.12015 ]
  }
]
