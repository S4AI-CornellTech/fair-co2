[
  {
    "build_commit": "4078c77f",
    "build_number": 4690,
    "cpu_info": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/Meta-Llama-3-8B/Meta-Llama-3-8B-F16.gguf",
    "model_type": "llama 8B F16",
    "model_size": 16061054976,
    "model_n_params": 8030261248,
    "n_batch": 1,
    "n_ubatch": 512,
    "n_threads": 48,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "tensor_split": "0.00",
    "use_mmap": true,
    "embeddings": false,
    "n_prompt": 128,
    "n_gen": 64,
    "test_time": "2025-02-17T06:41:29Z",
    "avg_ns": 74370732203,
    "stddev_ns": 1031118629,
    "avg_ts": 2.639451,
    "stddev_ts": 0.434331,
    "samples_ns": [ 73092025697, 74932952506, 71322549316, 93761823890, 58744309607 ],
    "samples_ts": [ 2.62683, 2.56229, 2.692, 2.04774, 3.2684 ]
  }
]

