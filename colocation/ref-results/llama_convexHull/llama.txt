[
  {
    "build_commit": "4078c77f",
    "build_number": 4690,
    "cpu_info": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/Meta-Llama-3-8B/Meta-Llama-3-8B-F16.gguf",
    "model_type": "llama 8B F16",
    "model_size": 16061054976,
    "model_n_params": 8030261248,
    "n_batch": 1,
    "n_ubatch": 512,
    "n_threads": 48,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "tensor_split": "0.00",
    "use_mmap": true,
    "embeddings": false,
    "n_prompt": 128,
    "n_gen": 64,
    "test_time": "2025-02-17T07:58:49Z",
    "avg_ns": 61801932856,
    "stddev_ns": 1036824432,
    "avg_ts": 3.107402,
    "stddev_ts": 0.052417,
    "samples_ns": [ 62062202391, 63146428241, 61762327523, 61793362252, 60245343875 ],
    "samples_ts": [ 3.09367, 3.04055, 3.10869, 3.10713, 3.18697 ]
  }
]
