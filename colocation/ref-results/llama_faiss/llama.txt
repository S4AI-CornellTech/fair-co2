[
  {
    "build_commit": "4078c77f",
    "build_number": 4690,
    "cpu_info": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/Meta-Llama-3-8B/Meta-Llama-3-8B-F16.gguf",
    "model_type": "llama 8B F16",
    "model_size": 16061054976,
    "model_n_params": 8030261248,
    "n_batch": 1,
    "n_ubatch": 512,
    "n_threads": 48,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "tensor_split": "0.00",
    "use_mmap": true,
    "embeddings": false,
    "n_prompt": 128,
    "n_gen": 64,
    "test_time": "2025-02-17T06:53:53Z",
    "avg_ns": 67208816093,
    "stddev_ns": 1372240474,
    "avg_ts": 3.783471,
    "stddev_ts": 1.865074,
    "samples_ns": [ 127799054659, 96171839978, 37357564774, 37456770529, 37258850528 ],
    "samples_ts": [ 1.50236, 1.99643, 5.13952, 5.12591, 5.15314 ]
  }
]
