[
  {
    "build_commit": "4078c77f",
    "build_number": 4690,
    "cpu_info": "Intel(R) Xeon(R) Gold 6240R CPU @ 2.40GHz",
    "gpu_info": "",
    "backends": "CPU",
    "model_filename": "models/Meta-Llama-3-8B/Meta-Llama-3-8B-F16.gguf",
    "model_type": "llama 8B F16",
    "model_size": 16061054976,
    "model_n_params": 8030261248,
    "n_batch": 1,
    "n_ubatch": 512,
    "n_threads": 48,
    "cpu_mask": "0x0",
    "cpu_strict": false,
    "poll": 50,
    "type_k": "f16",
    "type_v": "f16",
    "n_gpu_layers": 99,
    "split_mode": "layer",
    "main_gpu": 0,
    "no_kv_offload": false,
    "flash_attn": false,
    "tensor_split": "0.00",
    "use_mmap": true,
    "embeddings": false,
    "n_prompt": 128,
    "n_gen": 64,
    "test_time": "2025-02-16T23:30:35Z",
    "avg_ns": 51270958183,
    "stddev_ns": 565613907,
    "avg_ts": 3.947833,
    "stddev_ts": 0.949350,
    "samples_ns": [ 56020357745, 73029596889, 47955171719, 39912593910, 39437070652 ],
    "samples_ts": [ 3.42733, 2.62907, 4.00374, 4.81051, 4.86852 ]
  }
]
